# 术语表

这是一个由社区创建的术语表。欢迎大家贡献！

- **深度 Q-learning（Deep Q-Learning）：** 一种基于价值的深度强化学习算法，使用深度神经网络来近似给定状态下动作的Q值。深度Q学习的目标是通过学习动作值来找到最大化预期累积奖励的最优策略。

- **基于价值的方法（Value-based methods）：** 强化学习方法，估计价值函数作为找到最优策略的中间步骤。

- **基于策略的方法（Policy-based methods）：** 强化学习方法，直接学习近似最优策略，而不学习价值函数。在实践中，它们输出动作的概率分布。

    使用基于策略梯度方法相比基于价值的方法的好处包括：
    - 集成的简单性：无需存储动作值；
    - 学习随机策略的能力：代理探索状态空间时不总是采取相同的轨迹，避免了感知别名问题；
    - 在高维和连续动作空间中的有效性；以及
    - 改进的收敛性能。

- **策略梯度（Policy Gradient）：** 基于策略方法的一个子集，其目标是使用梯度上升来最大化参数化策略的性能。策略梯度的目标是通过调整策略来控制动作的概率分布，使得好的动作（最大化回报的动作）在未来更频繁地被采样。

- **蒙特卡罗强化（Monte Carlo Reinforce）：** 一种策略梯度算法，使用整个剧集的估计回报来更新策略参数。

如果你想改进课程，可以[打开一个拉取请求（Pull Request）](https://github.com/huggingface/deep-rl-class/pulls)。

感谢以下人员，本词汇表得以制作：

- [Diego Carpintero](https://github.com/dcarpintero)