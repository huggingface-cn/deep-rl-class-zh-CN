# 环境 SnowballTarget

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget.gif" alt="SnowballTarget"/>

SnowballTarget 是从 [Kay Lousberg](https://kaylousberg.com/) 在 Hugging Face 上创建的一个环境。**如果你想学习 Unity 去创建你的环境**，我们会在本单元末放置一个选择章节参考。

## 智能体的目标

第一个将要训练的智能体叫 Julien the bear 🐻。 其中 Julien 是用来训练**用雪球击打目标的**

在当前环境下的目标是让 Julien **在有限的时间下尽可能的击打目标(1000 时间戳)**。这需要**根据目标正确放置位置并且向目标射击**。

此外，为了避免 “滥发雪球” (也认为每一个时间戳都发射雪球)，** Julien 有一个“冷却”系统**(这需要等 0.5s 才可以发射下一枚雪球)


<figure>
<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/cooloffsystem.gif" alt="Cool Off System"/>
<figcaption>The agent needs to wait 0.5s before being able to shoot a snowball again</figcaption>
</figure>

## 奖励函数和奖励工程问题

奖励函数很简单，**每当智能体的小球击中目标，环境就会给一个 +1 的奖励**。因为智能体的目标是最大化期望累计奖励，**这会让他去击中尽可能多的目标**。


<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget_reward.png" alt="Reward system"/>

我们可以有一个更复杂的奖励函数（例如，通过惩罚来推动智能体走得更快）。但是当你设计一个环境时，你需要避免奖励工程问题，他有一个过于复杂的奖励函数来迫使你的智能体按照你想要的方式行事。为什么？因为那样做，你可能会**错过你的智能体通过更简单的奖励函数找到有趣策略**。

在代码方面，他看起来像这样：

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget-reward-code.png" alt="Reward"/>


## 观察空间

关于观察，我们不使用普通视觉（框架），而是**使用光线投射**。

将光线投射想象成激光，可以检测他们是否穿过物体。


<figure>
<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit5/raycasts.png" alt="Raycasts"/>
<figcaption>来源: <a href="https://github.com/Unity-Technologies/ml-agents">ML-Agents 文档</a></figcaption>
</figure>


在这个环境中，我们的智能体有多个光线投射集：
<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowball_target_raycasts.png" alt="Raycasts"/>

除了光线投射之外，智能体还会得到一个“我可以射击”布尔值作为观察值。

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget-obs-code.png" alt="Obs"/>

## 动作空间

动作空间是离散的：

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget_action_space.png" alt="Action Space"/>
