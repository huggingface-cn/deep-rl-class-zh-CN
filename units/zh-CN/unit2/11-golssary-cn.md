# RL术语词汇表

这是一个由社区创建的词汇表，欢迎投稿！

### 寻找最优策略的方法

- **基于策略的方法。** 策略通常用神经网络来训练，以选择在给定状态下采取的动作。在这种情况下，是神经网络输出了智能体应该采取的动作，而不是使用价值函数。根据环境给出的经验，神经网络会重新调整，并提供更好的动作。
- **基于价值的方法。** 在这种情况下，一个价值函数被训练来输出一个状态或一个状态-动作对的价值，这个价值将代表我们的策略。然而，这个价值并没有定义智能体应该采取什么动作。相反，我们需要指定智能体在给定价值函数的输出时的行为。例如，我们可以决定采用一个策略，其总是采取能够获得最大奖励的动作（贪婪策略）。总之，策略是一个贪婪策略（或者用户采取的任何决定），它使用价值函数的值来决定采取什么动作。

### 在基于价值的方法中，我们可以找到两种主要的策略

- **状态-价值函数。** 对于每个状态，状态-价值函数是如果智能体从当前状态开始，遵循该策略直到结束时的期望回报。
- **动作-价值函数。** 与状态-价值函数相比，动作-价值函数不仅考虑了状态，还考虑了在该状态下采取的动作，它计算了智能体在某个状态下执行某个动作后，根据策略所能获得的预期回报。之后智能体会一直遵循这个策略，以最大化回报。

### Epsilon-greedy 策略：

- 常用的强化学习探索策略，涉及平衡探索和利用。
- 以 1-epsilon 的概率选择奖励最高的动作。
- 以 epsilon 的概率选择一个随机动作。
- Epsilon 通常随着时间减少，以偏向利用。

### 贪婪策略：

- 涉及总是选择预期会导致最高奖励的动作，基于当前对环境的了解。（只有利用）
- 总是选择期望奖励最高的动作。
- 不包括任何探索。
- 在有不确定性或未知最优动作的环境中可能是不利的。


如果你想改进这门课程，你可以[提交一个 Pull Request.](https://github.com/huggingface/deep-rl-class/pulls)

本词汇表得以实现，感谢以下贡献者：

- [Ramón Rueda](https://github.com/ramon-rd)
- [Hasarindu Perera](https://github.com/hasarinduperera/)