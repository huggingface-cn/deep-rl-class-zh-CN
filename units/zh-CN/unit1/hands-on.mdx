# è®­ç»ƒä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ ğŸ¤– [[hands-on]]




      <CourseFloatingBanner classNames="absolute z-10 right-0 top-0"
      notebooks={[
        {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit1/unit1.ipynb"}
        ]}
        askForHelpUrl="http://hf.co/join/discord" />

ç°åœ¨ä½ å·²ç»å­¦ä¹ äº†å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ï¼Œä½ å·²ç»å‡†å¤‡å¥½è®­ç»ƒä½ çš„ç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“å¹¶é€šè¿‡ Hub ä¸ç¤¾åŒºåˆ†äº«å®ƒ ğŸ”¥ï¼š
ä½ å°†å­¦ä¼šæ­£ç¡®ç™»é™†æœˆçƒçš„æœˆçƒç€é™†å™¨æ™ºèƒ½ä½“ğŸŒ•

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/lunarLander.gif" alt="LunarLander">

æœ€åï¼Œä½ å°†**å°†è¿™ä¸ªè®­ç»ƒæœ‰ç´ çš„æ™ºèƒ½ä½“ä¸Šä¼ åˆ° Hugging Face Hub ğŸ¤—ï¼Œè¿™æ˜¯ä¸€ä¸ªå…è´¹çš„å¼€æ”¾å¹³å°ï¼Œäººä»¬å¯ä»¥åœ¨å…¶ä¸­å…±äº« ML æ¨¡å‹ã€æ•°æ®é›†å’Œæ¼”ç¤ºã€‚**

æ„Ÿè°¢ <a href="https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard">leaderboard</a>, ä½ å°†èƒ½å¤Ÿä¸å…¶ä»–åŒå­¦æ¯”è¾ƒä½ çš„ç»“æœå¹¶äº¤æµæœ€ä½³å®è·µä»¥æé«˜æ™ºèƒ½ä½“çš„åˆ†æ•°ã€‚è°å°†èµ¢å¾—ç¬¬ 1 å•å…ƒ ğŸ† çš„æŒ‘æˆ˜ï¼Ÿ

ä¸ºäº†æ‰‹åŠ¨éªŒè¯[è®¤è¯è¿‡ç¨‹](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process), ä½ éœ€è¦å°†ä½ è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ°Hubï¼Œå¹¶è·å¾—ç»“æœ >=200.

æ‰¾åˆ°ä½ çš„ç»“æœ å» [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) æ‰¾åˆ°ä½ çš„æ¨¡å‹, **ç»“æœ = å¹³å‡å¥–åŠ± - æ ‡å‡†å·®å¥–åŠ±**

**å¦‚æœä½ æ‰¾ä¸åˆ°ä½ çš„æ¨¡å‹ï¼Œè¯·è½¬åˆ°é¡µé¢åº•éƒ¨å¹¶ç‚¹å‡»åˆ·æ–°æŒ‰é’®ã€‚**

å…³äºæ›´å¤šè®¤è¯è¿‡ç¨‹ç‚¹å‡»å³è¾¹ ğŸ‘‰ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process

åŒæ—¶ä½ å¯ä»¥æŸ¥çœ‹ä½ çš„è¿‡ç¨‹ ğŸ‘‰ https://huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course

è®©æˆ‘ä»¬å¼€å§‹å§! ğŸš€

**ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹** ğŸ‘‡ :

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit1/unit1.ipynb)

æˆ‘ä»¬å¼ºçƒˆ**å»ºè®®å­¦ç”Ÿä½¿ç”¨ Google Colab è¿›è¡ŒåŠ¨æ‰‹ç»ƒä¹ **ï¼Œè€Œä¸æ˜¯åœ¨ä¸ªäººç”µè„‘ä¸Šè¿è¡Œå®ƒä»¬ã€‚

é€šè¿‡ä½¿ç”¨ Google Colabï¼Œ**ä½ å¯ä»¥ä¸“æ³¨äºå­¦ä¹ å’Œå®éªŒï¼Œè€Œä¸ç”¨æ‹…å¿ƒè®¾ç½®ç¯å¢ƒçš„æŠ€æœ¯é—®é¢˜**ã€‚

# ç¬¬ 1 å•å…ƒï¼šè®­ç»ƒä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ ğŸ¤–

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/thumbnail.jpg" alt="Unit 1 thumbnail" width="100%">

åœ¨æ­¤ç¬”è®°æœ¬ä¸­ï¼Œä½ å°†è®­ç»ƒä½ çš„**ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“**ä¸€ä¸ªæœˆçƒç€é™†å™¨æ™ºèƒ½ä½“ï¼Œå®ƒå°†å­¦ä¹ **æ­£ç¡®é™è½åœ¨æœˆçƒä¸ŠğŸŒ•**ã€‚ä½¿ç”¨ [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/) æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ï¼Œä¸ç¤¾åŒºåˆ†äº«ï¼Œå¹¶å°è¯•ä¸åŒçš„é…ç½®


### ç¯å¢ƒé…ç½® ğŸ®

- [LunarLander-v2](https://gymnasium.farama.org/environments/box2d/lunar_lander/)

### ä½¿ç”¨çš„åº“ ğŸ“š

- [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)

æˆ‘ä»¬ä¸€ç›´åœ¨åŠªåŠ›æ”¹è¿›æˆ‘ä»¬çš„æ•™ç¨‹ï¼Œæ‰€ä»¥**å¦‚æœä½ åœ¨æ­¤ç¬”è®°æœ¬ä¸­å‘ç°ä¸€äº›é—®é¢˜**ï¼Œè¯·[åœ¨ Github Repo ä¸Šæ‰“å¼€ä¸€ä¸ªé—®é¢˜](https://github.com/huggingface/deep-rl-class/issues)

## æœ¬ notebook çš„ç›®æ ‡ ğŸ†

æœ¬ç« ç»“æŸä½ å°†ä¼šå¾—åˆ°ä»¥ä¸‹çŸ¥è¯†ï¼š

- å­¦ä¼šä½¿ç”¨ç¯å¢ƒåº“ **Gymnasium**ã€‚
- å­¦ä¼šä½¿ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ **Stable-Baselines3**.
- å­¦ä¼šä½¿ç”¨æŠŠä½ çš„**æ™ºèƒ½ä½“æ¨é€åˆ°ä»“åº“**å¹¶åŒæ—¶å±•ç¤ºè§†é¢‘å’Œè¯„ä¼°åˆ†æ•° ğŸ”¥.


## æœ¬ notebook æ¥æºäºæ·±åº¦å­¦ä¹ æ•™ç¨‹

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg" alt="Deep RL Course illustration"/>

åœ¨æœ¬å…è´¹æ•™ç¨‹ä¸­ä½ å°†ä¼šå¾—åˆ°ï¼š

- ğŸ“– é€šè¿‡**ç†è®ºå’Œç»ƒä¹ **å­¦ä¹ æ·±åº¦å¼ºåŒ–å­¦ä¹ 
- ğŸ§‘â€ğŸ’» å­¦ä¼šä½¿ç”¨**ç»å…¸çš„å¼ºåŒ–å­¦ä¹ åº“**åƒ Stable Baselines3, RL Baselines3 Zoo, CleanRL å’Œ Sample Factory 2.0.
- ğŸ¤– åœ¨ç‰¹å®šç¯å¢ƒè®­ç»ƒ**æ™ºèƒ½ä½“**
- ğŸ“ å®Œæˆ80%çš„ä½œä¸šåï¼Œ**è·å¾—å®Œæˆè¯ä¹¦**ã€‚

è¿˜æœ‰æ›´å¤š

è¯·æŸ¥çœ‹ ğŸ“š æ•™å­¦å¤§çº² ğŸ‘‰ https://simoninithomas.github.io/deep-rl-course

åˆ«å¿˜äº† **<a href="http://eepurl.com/ic5ZUD">æ³¨å†Œæœ¬è¯¾ç¨‹</a>** (æˆ‘ä»¬æ­£åœ¨æ”¶é›†ä½ çš„ç”µå­é‚®ä»¶ï¼Œä»¥ä¾¿èƒ½å¤Ÿåœ¨å‘å¸ƒæ¯ä¸ªå•å…ƒæ—¶å‘**ä½ å‘é€é“¾æ¥ï¼Œå¹¶ä¸ºä½ æä¾›æœ‰å…³æŒ‘æˆ˜å’Œæ›´æ–°çš„ä¿¡æ¯).**

æœ€å¥½çš„ä¸æˆ‘ä»¬äº¤äº†ä¿æŒè”ç³»äº’åŠ¨çš„æ–¹å¼æ˜¯åŠ å…¥æˆ‘ä»¬çš„discordç¤¾åŒº ğŸ‘‰ğŸ» https://discord.gg/ydHrjt3WP5

## å‰ç½®å‡†å¤‡ ğŸ—ï¸

åœ¨å¼€å§‹å‰ä½ éœ€è¦:

ğŸ”² ğŸ“ **[é˜…è¯»å•å…ƒ 0](https://huggingface.co/deep-rl-course/unit0/introduction)** ç»™ä½ äº†æ‰€æœ‰å…³äºè¯¾ç¨‹çš„ä¿¡æ¯ç›¸å…³çš„é¡»çŸ¥å¹¶å¸®åŠ©ä½ è½»æ¾å¼€å§‹ğŸ¤—

ğŸ”² ğŸ“š é€šè¿‡é˜…è¯»[å•å…ƒ 1](https://huggingface.co/deep-rl-course/unit1/introduction)æ¥**ç†Ÿæ‚‰å¯¹å¼ºåŒ–å­¦ä¹ åŸºç¡€ï¼ˆ MC ï¼Œ TD ï¼Œå¥–åŠ±å‡è®¾...ï¼‰çš„ç†è§£**.

## æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å›é¡¾ ğŸ“š
<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/RL_process_game.jpg" alt="The RL process" width="100%">

è®©æˆ‘ä»¬å¯¹æˆ‘ä»¬åœ¨ç¬¬ä¸€ä¸ªå•å…ƒä¸­å­¦åˆ°çš„çŸ¥è¯†è¿›è¡Œå°å›é¡¾ï¼š

- å¼ºåŒ–å­¦ä¹ æ˜¯ä¸€ç§**ä»åŠ¨ä½œå­¦ä¹ **çš„è®¡ç®—æ–¹æ³•ã€‚æˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œé€šè¿‡**é€šè¿‡è¯•é”™**ä¸ç¯å¢ƒè¿›è¡Œäº’åŠ¨ï¼Œå¹¶è·å¾—å¥–åŠ±ï¼ˆè´Ÿæˆ–æ­£é¢ï¼‰ä½œä¸ºåé¦ˆã€‚

- ä»»ä½• RL æ™ºèƒ½ä½“çš„ç›®æ ‡æ˜¯**æœ€å¤§åŒ–å…¶æœŸæœ›çš„ç´¯ç§¯å¥–åŠ±**ï¼ˆä¹Ÿç§°ä¸ºæœŸæœ›å›æŠ¥ï¼‰ï¼Œå› ä¸º RL åŸºäº _å¥–åŠ±å‡è®¾_ï¼Œå³æ‰€æœ‰ç›®æ ‡éƒ½å¯ä»¥æè¿°ä¸ºæœ€å¤§åŒ–æœŸæœ›ç´¯ç§¯å¥–åŠ±ã€‚

- RL è¿‡ç¨‹æ˜¯ä¸€ä¸ª**å¾ªç¯ï¼Œè¯¥å¾ªç¯è¾“å‡ºä¸€ä¸ª **çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ± å’Œ ä¸‹ä¸€ä¸ªçŠ¶æ€çš„åºåˆ—ã€‚**


- ä¸ºäº†è®¡ç®—é¢„æœŸçš„ç´¯ç§¯å¥–åŠ±ï¼ˆæœŸæœ›å›æŠ¥ï¼‰ï¼Œæˆ‘ä»¬å¯¹å¥–åŠ±è¿›è¡ŒæŠ˜æ‰£ï¼šè¾ƒæ—©å‡ºç°çš„å¥–åŠ±ï¼ˆåœ¨æ¸¸æˆå¼€å§‹æ—¶ï¼‰**æ›´æœ‰å¯èƒ½å‘ç”Ÿï¼Œå› ä¸ºå®ƒä»¬æ¯”é•¿æœŸçš„æœªæ¥å¥–åŠ±æ›´å¯é¢„æµ‹ã€‚* *

- è¦è§£å†³ RL é—®é¢˜ï¼Œä½ éœ€è¦**æ‰¾åˆ°æœ€ä¼˜ç­–ç•¥**ã€‚è¯¥ç­–ç•¥æ˜¯ä½ æ™ºèƒ½ä½“çš„â€œå¤§è„‘â€ï¼Œå®ƒå°†å‘Šè¯‰æˆ‘ä»¬**åœ¨ç»™å®šçŠ¶æ€ä¸‹é‡‡å–ä»€ä¹ˆåŠ¨ä½œã€‚**æœ€ä¼˜ç­–ç•¥**ä¸ºä½ æä¾›äº†æœ€å¤§åŒ–æœŸæœ›å›æŠ¥çš„åŠ¨ä½œã€‚**

æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥æ‰¾åˆ°ä½ çš„æœ€ä½³ç­–ç•¥ï¼š

- é€šè¿‡ç›´æ¥è®­ç»ƒä½ çš„ç­–ç•¥ï¼š**åŸºäºç­–ç•¥çš„æ–¹æ³•ã€‚**
- é€šè¿‡è®­ç»ƒä¸€ä¸ªä»·å€¼å‡½æ•°æ¥å‘Šè¯‰æˆ‘ä»¬æ™ºèƒ½ä½“åœ¨æ¯ä¸ªçŠ¶æ€ä¸‹å°†è·å¾—çš„é¢„æœŸå›æŠ¥ï¼Œå¹¶ä½¿ç”¨è¿™ä¸ªå‡½æ•°æ¥å®šä¹‰æˆ‘ä»¬çš„ç­–ç•¥ï¼š**åŸºäºä»·å€¼çš„æ–¹æ³•ã€‚**

- æœ€åï¼Œæˆ‘ä»¬è°ˆåˆ°æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼Œå› ä¸ºæˆ‘ä»¬å¼•å…¥äº†**æ·±åº¦ç¥ç»ç½‘ç»œæ¥ä¼°è®¡è¦é‡‡å–çš„åŠ¨ä½œï¼ˆåŸºäºç­–ç•¥ï¼‰æˆ–ä¼°è®¡çŠ¶æ€çš„ä»·å€¼ï¼ˆåŸºäºä»·å€¼ï¼‰ï¼Œå› æ­¤å¾—åâ€œæ·±åº¦â€ã€‚**

# è®©æˆ‘ä»¬è®­ç»ƒæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼Œç„¶åå°†å…¶ä¸Šä¼ åˆ° hub ğŸš€

## è·å¾—è¯ä¹¦ ğŸ“

ä¸ºäº†éªŒè¯è¿™ä¸ªå®è·µç»ƒä¹ å¹¶é€šè¿‡[è®¤è¯æµç¨‹](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)ï¼Œä½ éœ€è¦å°†ä½ è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ° Hub å¹¶ä¸”**è·å¾—å¤§äºç­‰äº 200 çš„ç»“æœ**ã€‚

è¦æŸ¥çœ‹ä½ çš„ç»“æœï¼Œè¯·å‰å¾€[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)å¹¶æ‰¾åˆ°ä½ çš„æ¨¡å‹ï¼Œ**ç»“æœ = å¹³å‡å¥–åŠ± - å¥–åŠ±çš„æ ‡å‡†å·®**

æœ‰å…³è®¤è¯æµç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ†ğŸ‘‰ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process


## è®¾ç½® GPU ğŸ’ª

- ä¸ºäº†**åŠ é€Ÿæ™ºèƒ½ä½“è®­ç»ƒ,æˆ‘ä»¬å°†ä¼šç”¨åˆ° GPU **ã€‚è¿™é‡Œè®¾ç½® `Runtime > Change Runtime type`

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg" alt="GPU Step 1">

- `Hardware Accelerator > GPU`

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg" alt="GPU Step 2">

## å®‰è£…ä¾èµ–å¹¶åˆ›å»ºè™šæ‹Ÿå±å¹• ğŸ”½
ç¬¬ä¸€æ­¥æ˜¯å®‰è£…ç›¸å…³ä¾èµ–ï¼Œæˆ‘ä»¬å°†ä¼šå®‰è£…å¤šé¡¹

- `gymnasium[box2d]`: åŒ…å« Lunarlander-V2 ç¯å¢ƒğŸŒ›ã€‚
- `stable-baselines3[extra]`: æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ã€‚
- `huggingface_sb3`: ç¨³å®šçš„ baselines3 çš„å…¶ä»–ä»£ç ï¼Œå¯ä» huggingfaceğŸ¤— ä»“åº“ä¸ŠåŠ è½½å’Œä¸Šä¼ æ¨¡å‹ã€‚

ä¸ºäº†ç®€åŒ–æ“ä½œï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªè„šæœ¬å®‰è£…æ‰€æœ‰ä¾èµ–


```bash
apt install swig cmake
```


```bash
pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt
```

åœ¨ notebook ä¸Šï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆä¸€ä¸ªé‡æ’­è§†é¢‘ã€‚ä¸ºæ­¤ï¼Œä½¿ç”¨ Colab ï¼Œ**æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªè™šæ‹Ÿå±å¹•æ‰èƒ½æ¸²æŸ“ç¯å¢ƒ**ï¼ˆä»è€Œè®°å½•å¸§ï¼‰ã€‚

å› æ­¤ï¼Œä»¥ä¸‹å•å…ƒæ ¼å°†å®‰è£…è™šæ‹Ÿå±å¹•åº“ï¼Œå¹¶åˆ›å»ºå¹¶è¿è¡Œè™šæ‹Ÿå±å¹•ğŸ–¥


```bash
sudo apt-get update
apt install python-opengl
apt install ffmpeg
apt install xvfb
pip3 install pyvirtualdisplay
```

ä¸ºäº†ç¡®ä¿ä½¿ç”¨æ–°çš„å·²å®‰è£…åº“ï¼Œ**æœ‰æ—¶éœ€è¦é‡æ–°å¯åŠ¨ç¬”è®°æœ¬è¿è¡Œæ—¶**ã€‚ä¸‹ä¸€ä¸ªå•å…ƒå°†è¿«ä½¿**è¿è¡Œæ—¶å´©æºƒï¼Œå› æ­¤ä½ éœ€è¦å†æ¬¡è¿æ¥å¹¶ä»è¿™é‡Œå¼€å§‹è¿è¡Œä»£ç ã€‚æ„Ÿè°¢è¿™ä¸ªæŠ€å·§ï¼Œ**æˆ‘ä»¬å°†èƒ½å¤Ÿè¿è¡Œè™šæ‹Ÿå±å¹•ã€‚**


```python
import os

os.kill(os.getpid(), 9)
```


```python
# Virtual display
from pyvirtualdisplay import Display

virtual_display = Display(visible=0, size=(1400, 900))
virtual_display.start()
```

## å¯¼å…¥ç›¸å…³åŒ… ğŸ“¦

æˆ‘ä»¬å¯¼å…¥çš„å¦ä¸€ä¸ªåº“æ˜¯ huggingface_hub **ï¼Œèƒ½å¤Ÿä»ä»“åº“ä¸Šä¼ å’Œä¸‹è½½è®­ç»ƒæœ‰ç´ çš„æ¨¡å‹**ã€‚


huggingface ä»“åº“ğŸ¤—æ˜¯ä»»ä½•äººéƒ½å¯ä»¥å…±äº«å’Œæ¢ç´¢æ¨¡å‹å’Œæ•°æ®é›†çš„ä¸­å¿ƒåœ°ç‚¹ã€‚å®ƒå…·æœ‰ç‰ˆæœ¬æ§åˆ¶ï¼ŒæŒ‡æ ‡ï¼Œå¯è§†åŒ–å’Œå…¶ä»–åŠŸèƒ½ï¼Œå¯è®©ä½ è½»æ¾ä¸ä»–äººåˆä½œ

è¿™é‡Œå¯ä»¥çœ‹åˆ°æ‰€æœ‰å¯ç”¨çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ ğŸ‘‰ https://huggingface.co/models?pipeline_tag=reinforcement-learning&sort=downloads




```python
import gymnasium

from huggingface_sb3 import load_from_hub, package_to_hub
from huggingface_hub import (
    notebook_login,
)  # To log to our Hugging Face account to be able to upload models to the Hub.

from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.monitor import Monitor

```

## ç†è§£ä»€ä¹ˆæ˜¯ Gymnasium å¹¶ä¸”ä»–æ€ä¹ˆå·¥ä½œçš„ğŸ¤–

ğŸ‹ åŒ…å«æˆ‘ä»¬è¿è¡Œç¯å¢ƒçš„åº“å« Gymnasium.
**ä½ å°†åœ¨æ·±åº¦å¼ºåŒ–å­¦ä¹ é¢†åŸŸå¤šæ¬¡ç”¨åˆ°è¯¥åº“**

Gymnasium åº“æä¾›äº†ä¸¤ä¸ªäº‹æƒ…ï¼š
- ä¸€ä¸ªäº¤äº’ç•Œé¢å…è®¸ä½ **åˆ›å»ºå¼ºåŒ–å­¦ä¹ ç¯å¢ƒ**.
- ä¸€ä¸ª**ç¯å¢ƒé›†åˆ** ( gym-control, atari, box2D...).

è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ï¼Œé¦–å…ˆæˆ‘ä»¬äº†è§£ä¸€ä¸‹ä»€ä¹ˆæ˜¯ RL å¾ªç¯.

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/RL_process_game.jpg" alt="The RL process" width="100%">

æ¯ä¸€æ­¥:
- æˆ‘ä»¬çš„æ™ºèƒ½ä½“ä»**ç¯å¢ƒ**æ¥æ”¶**çŠ¶æ€ S0** - æˆ‘ä»¬å°†æ”¶åˆ°æ¸¸æˆçš„ç¬¬ä¸€å¸§ï¼ˆç¯å¢ƒï¼‰ã€‚
- åŸºäº**çŠ¶æ€ S0ï¼Œ**æ™ºèƒ½ä½“é‡‡å– **åŠ¨ä½œ A0** - æˆ‘ä»¬çš„æ™ºèƒ½ä½“å°†ç§»åŠ¨åˆ°å³è¾¹
- ç¯å¢ƒå°†å˜æˆä¸€ä¸ª**æ–°**çš„**çŠ¶æ€ S1**ï¼ˆæ–°çš„ä¸€å¸§ï¼‰.
- ç¯å¢ƒç»™æ™ºèƒ½ä½“æä¾›äº†ä¸€äº›**å¥–åŠ± R1 ** - æˆ‘ä»¬è¿˜æ²¡æœ‰æ­»*ï¼ˆæ­£å¥–åŠ± +1ï¼‰*ã€‚.


é€šè¿‡ Gymnasium:

1ï¸âƒ£ æˆ‘ä»¬ä½¿ç”¨  `gymnasium.make()`  åˆ›å»ºç¯å¢ƒ

2ï¸âƒ£ æˆ‘ä»¬ä½¿ç”¨  `observation = env.reset()` é‡è®¾ç¯å¢ƒåˆå§‹çŠ¶æ€

åœ¨æ¯ä¸€æ­¥:

3ï¸âƒ£ ä½¿ç”¨æ¨¡å‹è·å–åŠ¨ä½œ(æˆ‘ä»¬çš„ä¾‹å­é‡Œä½¿ç”¨éšæœºåŠ¨ä½œ)

4ï¸âƒ£ ä½¿ç”¨  `env.step(action)` , æˆ‘ä»¬å±•ç¤ºäº†åŠ¨ä½œåœ¨ç¯å¢ƒä¸­æ€ä¹ˆè·å¾—
- `observation`: æ–°çŠ¶æ€  (st+1)
- `reward`: æ‰§è¡ŒåŠ¨ä½œåçš„å¥–åŠ±
- `terminated`ï¼šè¡¨ç¤ºè¯¥å›åˆæ˜¯å¦ç»ˆæ­¢ï¼ˆæ™ºèƒ½ä½“åˆ°è¾¾æœ€ç»ˆçŠ¶æ€ï¼‰
- `truncated`ï¼šåœ¨è¿™ä¸ªæ–°ç‰ˆæœ¬ä¸­å¼•å…¥ï¼Œå®ƒè¡¨ç¤ºæ—¶é—´é™åˆ¶æˆ–è€…ä»£ç†æ˜¯å¦è¶…å‡ºç¯å¢ƒçš„è¾¹ç•Œã€‚
- `info`ï¼šæä¾›é¢å¤–ä¿¡æ¯çš„å­—å…¸ï¼ˆå–å†³äºç¯å¢ƒï¼‰ã€‚

æœ‰å…³æ›´å¤šè§£é‡Šï¼Œè¯·æŸ¥çœ‹è¿™é‡ŒğŸ‘‰ https://gymnasium.farama.org/api/env/#gymnasium.Env.step

å¦‚æœè¿™ä¸ªå›åˆç»“æŸ:
- æˆ‘ä»¬é‡è®¾ç¯å¢ƒåˆå§‹çŠ¶æ€  `observation = env.reset()`

**è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­!** ç¡®ä¿ä½ è¯»äº†ä»£ç 

```python
import gymnasium as gym

# é¦–å…ˆï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå« LunarLander-v2 çš„ç¯å¢ƒ
env = gym.make("LunarLander-v2")

# ç„¶åæˆ‘ä»¬é‡ç½®ä¸€ä¸‹ç¯å¢ƒ
observation, info = env.reset()

for _ in range(20):
    # Take a random action
    action = env.action_space.sample()
    print("Action taken:", action)

    # Do this action in the environment and get
    # next_state, reward, terminated, truncated and info
    observation, reward, terminated, truncated, info = env.step(action)

    # If the game is terminated (in our case we land, crashed) or truncated (timeout)
    if terminated or truncated:
        # Reset the environment
        print("Environment is reset")
        observation, info = env.reset()

env.close()
```

## åˆ›å»ºæœˆçƒå‘å°„å™¨ç¯å¢ƒğŸŒ›å¹¶äº†è§£å…¶å·¥ä½œåŸç†

### [ç¯å¢ƒ ğŸ®](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)
åœ¨æœ¬æ•™ç¨‹ä¸­, æˆ‘ä»¬è¦è®­ç»ƒä¸€ä¸ªæ™ºèƒ½ä½“, ä¸€ä¸ª**æ­£ç¡®ç€é™†åœ¨æœˆçƒ**çš„ [æœˆçƒå‘å°„å™¨](https://gymnasium.farama.org/environments/box2d/lunar_lander/) . ä¸ºæ­¤ï¼Œæ™ºèƒ½ä½“éœ€è¦å­¦ä¹ **ä»¥é€‚åº”å…¶é€Ÿåº¦å’Œä½ç½®ï¼ˆæ°´å¹³ï¼Œå‚ç›´å’Œè§’åº¦ï¼‰æ‰èƒ½æ­£ç¡®é™è½ã€‚**

---


ğŸ’¡ å¯åŠ¨ç¯å¢ƒå¹¶æ£€æŸ¥ç›¸å…³æ–‡æ¡£æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ 

ğŸ‘‰ https://gymnasium.farama.org/environments/box2d/lunar_lander/

---


è®©æˆ‘ä»¬çœ‹çœ‹ç¯å¢ƒå•¥æ ·


```python
# We create our environment with gym.make("<name_of_the_environment>")
env = gym.make("LunarLander-v2")
env.reset()
print("_____OBSERVATION SPACE_____ \n")
print("Observation Space Shape", env.observation_space.shape)
print("Sample observation", env.observation_space.sample()) # Get a random observation
```

æˆ‘ä»¬çœ‹åˆ° `Observation Space Shape (8,)`æ˜¯ä¸€ä¸ªå°ºå¯¸ 8 çš„å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå€¼åŒ…å«æœ‰å…³ç€é™†å™¨çš„ä¸åŒä¿¡æ¯ï¼š
- æ°´å¹³å«åæ ‡ï¼ˆ x ï¼‰
- å‚ç›´å«åæ ‡ï¼ˆ y ï¼‰
- æ°´å¹³é€Ÿåº¦ï¼ˆ x ï¼‰
- å‚ç›´é€Ÿåº¦ï¼ˆ y ï¼‰
- è§’åº¦
- è§’é€Ÿåº¦
- å¦‚æœå·¦è…¿æœ‰æ¥è§¦ç‚¹è§¦åŠåœŸåœ°
- å¦‚æœå³è…¿æœ‰æ¥è§¦ç‚¹è§¦åŠåœŸåœ°



```python
print("\n _____ACTION SPACE_____ \n")
print("Action Space Shape", env.action_space.n)
print("Action Space Sample", env.action_space.sample()) # Take a random action
```

åŠ¨ä½œç©ºé—´ï¼ˆæ™ºèƒ½ä½“å¯ä»¥é‡‡å–çš„å¯èƒ½çš„æ“ä½œé›†ï¼‰æ˜¯ç¦»æ•£çš„ï¼Œæœ‰ 4 ä¸ªå¯ç”¨çš„æ“ä½œğŸ®ï¼š

- åŠ¨ä½œ 0ï¼šæ²¡åšä»€ä¹ˆï¼Œ
- åŠ¨ä½œ 1ï¼šç‚¹ç«å·¦å®šå‘å¼•æ“ï¼Œ
- åŠ¨ä½œ 2ï¼šå‘å°„ä¸»å¼•æ“ï¼Œ
- åŠ¨ä½œ 3ï¼šç‚¹ç«å³å‘å®šå‘å¼•æ“ã€‚ã€‚

å¥–åŠ±å‡½æ•°ï¼ˆåœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¸­éƒ½ä¼šè·å¾—å¥–åŠ±çš„å‡½æ•°ï¼‰ğŸ’°ï¼š

æ¯ä¸€æ­¥éƒ½ä¼šè·å¾—å¥–åŠ±ã€‚ä¸€ä¸ªå›åˆçš„æ€»å¥–åŠ±æ˜¯**è¯¥å›åˆå†…æ‰€æœ‰æ­¥éª¤çš„å¥–åŠ±ä¹‹å’Œ**ã€‚

å¯¹äºæ¯ä¸€æ­¥ï¼Œå¥–åŠ±ï¼š

- éšç€ç€é™†å™¨ç¦»ç€é™†å«è¶Šè¿‘/è¶Šè¿œè€Œå¢åŠ /å‡å°‘ã€‚
- éšç€ç€é™†å™¨ç§»åŠ¨å¾—è¶Šæ…¢/è¶Šå¿«è€Œå¢åŠ /å‡å°‘ã€‚
- éšç€ç€é™†å™¨å€¾æ–œå¾—è¶Šå¤šï¼ˆè§’åº¦ä¸æ°´å¹³ï¼‰è€Œå‡å°‘ã€‚
- æ¯ä¸ªä¸åœ°é¢æ¥è§¦çš„è…¿å¢åŠ  10 åˆ†ã€‚
- æ¯å¸§ä¾§é¢å‘åŠ¨æœºç‚¹ç«å‡å°‘ 0.03 åˆ†ã€‚
- æ¯å¸§ä¸»å‘åŠ¨æœºç‚¹ç«å‡å°‘ 0.3 åˆ†ã€‚

å›åˆ**å› å æ¯æˆ–å®‰å…¨ç€é™†åˆ†åˆ«è·å¾—é¢å¤–çš„ -100 æˆ– +100 åˆ†çš„å¥–åŠ±**ã€‚

å¦‚æœä¸€ä¸ªå›åˆ**å¾—åˆ†è‡³å°‘ 200 åˆ†ï¼Œåˆ™è®¤ä¸ºå®ƒæ˜¯ä¸€ä¸ªè§£å†³æ–¹æ¡ˆ**ã€‚

#### å‘é‡åŒ–ç¯å¢ƒ

- æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªç”± 16 ä¸ªç¯å¢ƒç»„æˆçš„å‘é‡åŒ–ç¯å¢ƒï¼ˆä¸€ç§å°†å¤šä¸ªç‹¬ç«‹ç¯å¢ƒå †å åˆ°ä¸€ä¸ªç¯å¢ƒä¸­çš„æ–¹æ³•ï¼‰ï¼Œè¿™æ ·ï¼Œåœ¨è®­ç»ƒæœŸé—´æˆ‘ä»¬å°†æ‹¥æœ‰æ›´å¤šæ ·çš„ç»éªŒã€‚


```python
# åˆ›å»ºç¯å¢ƒ
env = make_vec_env('LunarLander-v2', n_envs=16)
```

## åˆ›å»ºæ¨¡å‹ğŸ¤–

- ç°åœ¨æˆ‘ä»¬ç ”ç©¶äº†æˆ‘ä»¬çš„ç¯å¢ƒï¼Œå¹¶äº†è§£äº†é—®é¢˜ï¼š**èƒ½å¤Ÿé€šè¿‡æ§åˆ¶å·¦ï¼Œå³å’Œä¸»è¦æ–¹å‘å¼•æ“**å°†æœˆçƒç€é™†å™¨æ­£ç¡®åœ°é™è½åˆ°ç€é™†å«ä¸Šã€‚è®©æˆ‘ä»¬æ„å»ºæˆ‘ä»¬å°†ç”¨æ¥è§£å†³æ­¤é—®é¢˜çš„ç®—æ³•ã€‚

- ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç¬¬ä¸€ä¸ªæ·±åº¦ RL åº“[stable Baselines3ï¼ˆsb3ï¼‰]ï¼ˆhttps://stable-baselines3.readthedocs.io/en/master/ï¼‰ã€‚

- SB3 æ˜¯ PyTorch **ä¸­å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„ä¸€ç»„å¯é çš„å®ç°**ã€‚

---
ğŸ’¡ä½¿ç”¨åº“æ—¶ï¼Œä¸€ä¸ªå¥½ä¹ æƒ¯æ˜¯é¦–å…ˆæŸ¥çœ‹æ–‡æ¡£ï¼š httpsï¼š//stable-baselines3.readthedocs.io/en/master/ ï¼Œç„¶åå°è¯•ä¸€äº›æ•™ç¨‹ã€‚

---

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/sb3.png" alt="Stable Baselines3">

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ SB3 ** PPO **ã€‚[PPOï¼ˆåˆç§°è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼‰æ˜¯ä½ åœ¨æœ¬è¯¾ç¨‹ä¸­ä½ å°†ç ”ç©¶çš„æ·±åº¦å¼ºåŒ–å­¦ä¹  SOTA ç®—æ³•ä¹‹ä¸€](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#example%5D)ã€‚

PPO ç»“åˆäº†ä¸‹é¢ï¼š

- *åŸºäºä»·å€¼çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•*ï¼šå­¦ä¹ ä¸€ä¸ªåŠ¨ä½œä»·å€¼å‡½æ•°ï¼Œè¯¥åŠŸèƒ½å°†å‘Šè¯‰æˆ‘ä»¬**ç»™å®šä¸€ä¸ªçŠ¶æ€å’ŒåŠ¨ä½œæ—¶ï¼Œæœ€æœ‰ä»·å€¼çš„è¡ŒåŠ¨**ã€‚
- *åŸºäºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•*ï¼šå­¦ä¹ ä¸€ä¸ªç­–ç•¥ï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿç»™æˆ‘ä»¬åŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒ**ã€‚

Stable-Baselines3 ç®€æ˜“è®¾ç½®:

1ï¸âƒ£  **åˆ›å»ºç¯å¢ƒ** (ä¸Šæ–‡å·²å®Œæˆ)

2ï¸âƒ£ å®šä¹‰ **ä½ æƒ³ç”¨çš„æ¨¡å‹å¹¶ä¸”å®ä¾‹åŒ–** `model = PPO("MlpPolicy")`

3ï¸âƒ£ é€šè¿‡ `model.learn` è®­ç»ƒä½ çš„æ™ºèƒ½ä½“å¹¶ä¸”å®šä¹‰è®­ç»ƒæ­¥æ•°

```python
# åˆ›å»ºç¯å¢ƒ
env = gym.make('LunarLander-v2')

# åˆå§‹åŒ–æ™ºèƒ½ä½“
model = PPO('MlpPolicy', env, verbose=1)
# è®­ç»ƒæ™ºèƒ½ä½“
model.learn(total_timesteps=int(2e5))
```


```python
# ç›®æ ‡: å®šä¹‰ä¸€ä¸ª PPO MLP ç­–ç•¥ç»“æ„
# å› ä¸ºè¾“å…¥æ˜¯ä¸€ä¸ªå‘é‡æˆ‘ä»¬ä½¿ç”¨ MLP
# å¦‚æœæˆ‘ä»¬è¾“å…¥æ˜¯å¸§ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ CNN ç­–ç•¥
model = 
```

#### è§£å†³æ–¹æ¡ˆ


```python
# è§£å†³æ–¹æ¡ˆ
# æˆ‘ä»¬æ·»åŠ äº†ä¸€äº›å‚æ•°å»åŠ é€Ÿè®­ç»ƒ
model = PPO(
    policy = 'MlpPolicy',
    env = env,
    n_steps = 1024,
    batch_size = 64,
    n_epochs = 4,
    gamma = 0.999,
    gae_lambda = 0.98,
    ent_coef = 0.01,
    verbose=1)
```

##è®­ç»ƒ PPO æ™ºèƒ½ä½“ğŸƒ

- è®©æˆ‘ä»¬è®­ç»ƒæˆ‘ä»¬çš„æ™ºèƒ½ä½“ä»¥1,000,000ä¸ªæ—¶é—´æ­¥é•¿è®­ç»ƒï¼Œä¸è¦å¿˜è®°åœ¨ COLAB ä¸Šä½¿ç”¨ GPU ã€‚å¤§çº¦éœ€è¦çº¦ 20 åˆ†é’Ÿï¼Œä½†æ˜¯å¦‚æœä½ åªæƒ³å°è¯•ä¸€ä¸‹ï¼Œå°±å¯ä»¥ä½¿ç”¨æ›´å°‘çš„æ—¶é—´æ­¥æ•°ã€‚

- åœ¨è®­ç»ƒæœŸé—´ï¼Œä¼‘æ¯ä¸€ä¸‹ğŸ¤—


```python
# ç›®æ ‡: è®­ç»ƒ 1,000,000 æ—¶é—´æ­¥é•¿

# ç›®æ ‡: æ”¹åå­—å¹¶å°†æ¨¡å‹å­˜å…¥æ–‡ä»¶
model_name = ""

```

#### è§£å†³æ–¹æ¡ˆ


```python
# è§£å†³æ–¹æ¡ˆ
# è®­ç»ƒ 1,000,000 æ—¶é—´æ­¥é•¿
model.learn(total_timesteps=1000000)
# ä¿å­˜æ¨¡å‹
model_name = "ppo-LunarLander-v2"
model.save(model_name)
```

## è¯„ä¼°æ™ºèƒ½ä½“ğŸ“ˆ

- ç°åœ¨æˆ‘ä»¬çš„æœˆçƒå‘å°„å™¨æ™ºèƒ½ä½“æ¥å—äº†è®­ç»ƒğŸš€ï¼Œæˆ‘ä»¬éœ€è¦**æ£€æŸ¥å…¶æ€§èƒ½**ã€‚

- ç¨³å®šçš„ baselines3 æä¾›äº†ä¸€ç§æ–¹æ³•ï¼š`evaluate_policy`ã€‚

- è¦å®Œæˆè¯¥éƒ¨åˆ†ï¼Œä½ éœ€è¦[æŸ¥é˜…æ–‡æ¡£]ï¼ˆhttps://stable-baselines3.readthedocs.io/en/master/guide/guide/guide/examples.html#basic-usage-usage-usage-usage-training-saving-loadingï¼‰

- åœ¨ä¸‹ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°**å¦‚ä½•è‡ªåŠ¨è¯„ä¼°å’Œåˆ†äº«ä½ çš„æ™ºèƒ½ä½“åœ¨æ’è¡Œæ¦œä¸­ç«äº‰ï¼Œä½†ç°åœ¨è®©æˆ‘ä»¬è‡ªå·±åš**

ğŸ’¡å½“ä½ è¯„ä¼°æ™ºèƒ½ä½“æ—¶ï¼Œä½ ä¸åº”ä½¿ç”¨è®­ç»ƒç¯å¢ƒï¼Œè€Œåº”åˆ›å»ºè¯„ä¼°ç¯å¢ƒã€‚


```python
# ç›®æ ‡: è¯„ä¼°æ™ºèƒ½ä½“
# ä¸ºè¯„ä¼°åˆ›å»ºä¸€ä¸ªæ–°ç¯å¢ƒ
eval_env =

# ç”¨ 10 ä¸ªè¯„ä¼°å›åˆå’Œ deterministic=True çš„æ¡ä»¶å»è¯„ä¼°æ¨¡å‹
mean_reward, std_reward = 

# æ‰“å°ç»“æœ


```

#### è§£å†³æ–¹æ¡ˆ


```python
#@title
eval_env = Monitor(gym.make("LunarLander-v2"))
mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)
print(f"mean_reward={mean_reward:.2f} +/- {std_reward}")
```

- å°±æˆ‘è€Œè¨€ï¼Œåœ¨è®­ç»ƒ 100 ä¸‡æ­¥ä¹‹åï¼Œæˆ‘è·å¾—äº†å¹³å‡å¥–åŠ±æ˜¯ `200.20 +/- 20.80` ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬çš„æœˆçƒç€é™†å™¨ï¼ˆLunar Landerï¼‰æ™ºèƒ½ä½“å‡†å¤‡åœ¨æœˆçƒä¸Šé™è½ã€‚

## åœ¨ä»“åº“ä¸Šå‘å¸ƒæˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹ğŸ”¥

ç°åœ¨ï¼Œæˆ‘ä»¬çœ‹åˆ°è®­ç»ƒåæˆ‘ä»¬è·å¾—äº†è‰¯å¥½çš„æˆç»©ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€æ¡ä»£ç åœ¨ä»“åº“ä¸Šå‘å¸ƒå·²ç»è®­ç»ƒçš„æ¨¡å‹ã€‚

ğŸ“šåº“æ–‡æ¡£ğŸ‘‰https://github.com/huggingface/huggingface_sb3/tree/main#hugging-face-face--x-stable-baselines3-v20

è¿™æ˜¯æ¨¡å‹å¡ç‰‡çš„ç¤ºä¾‹ï¼ˆå¸¦æœ‰å¤ªç©ºå…¥ä¾µè€…ï¼‰ï¼š

é€šè¿‡ä½¿ç”¨ `package_to_hub` **ä½ è¯„ä¼°ï¼Œè®°å½•ä¸€ä¸ªé‡æ¼”ï¼Œç”Ÿæˆæ™ºèƒ½ä½“çš„æ¨¡å‹å¡ç‰‡å¹¶å°†å…¶æ¨åˆ°ä»“åº“**ã€‚

è¿™è¾¹ï¼š

- ä½ å¯ä»¥**å±•ç¤ºæˆ‘ä»¬çš„ä½œå“**ğŸ”¥

- ä½ å¯ä»¥**å¯è§†åŒ–ä½ çš„æ™ºèƒ½ä½“**ğŸ‘€

- ä½ å¯ä»¥**ä¸ç¤¾åŒºåˆ†äº«å…¶ä»–äººå¯ä»¥ä½¿ç”¨**ğŸ’¾çš„æ™ºèƒ½ä½“

- ä½ å¯ä»¥**åœ¨ leaderboard ğŸ†æŸ¥çœ‹ä¸åŒå­¦ç›¸æ¯”ä½ çš„æ™ºèƒ½ä½“çš„è¡¨ç°å¦‚ä½•** ğŸ‘‰ https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard

ä¸ºäº†èƒ½å¤Ÿä¸ç¤¾åŒºåˆ†äº«ä½ çš„æ¨¡å‹ï¼Œè¿˜æœ‰ä¸‰ä¸ªæ­¥éª¤å¯ä»¥éµå¾ªï¼š

1ï¸âƒ£ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰åˆ›å»ºä¸€ä¸ªå¸æˆ·åˆ° HF https://huggingface.co/join

2ï¸âƒ£ ç™»å½•ï¼Œç„¶åä½ éœ€è¦ä» huggingface ç½‘ç«™å­˜å‚¨èº«ä»½éªŒè¯ä»¤ç‰Œã€‚

- åˆ›å»ºä¸€ä¸ªæ–°çš„ä»¤ç‰Œï¼ˆhttps://huggingface.co/settings/tokensï¼‰**å¸¦æœ‰å†™æƒé™**

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg" alt="Create HF Token">

- å¤åˆ¶ä»¤ç‰Œ
- åœ¨ä¸‹é¢è¿è¡Œå•å…ƒæ ¼å¹¶ç²˜è´´ä»¤ç‰Œ


```python
notebook_login()
!git config --global credential.helper store
```

å¦‚æœä½ ä¸æƒ³ä½¿ç”¨ Google Colab æˆ– Jupyter ç¬”è®°æœ¬ï¼Œåˆ™éœ€è¦ä½¿ç”¨æ­¤å‘½ä»¤ï¼š`huggingface-cli login`

3ï¸âƒ£æˆ‘ä»¬ç°åœ¨ä½¿ç”¨ `package_to_hubï¼ˆï¼‰` å‡½æ•°å°†è®­ç»ƒçš„æ™ºèƒ½ä½“æ¨åˆ° hunggingfaceğŸ¤— ä»“åº“ğŸ”¥

è®©æˆ‘ä»¬å¡«å†™ `package_to_hub` å‡½æ•°ï¼š

- `model`ï¼šæˆ‘ä»¬è®­ç»ƒæœ‰ç´ çš„æ¨¡å‹ã€‚

- `model_name`ï¼šæˆ‘ä»¬åœ¨``model_save''ä¸­å®šä¹‰çš„è®­ç»ƒæ¨¡å‹çš„åç§°

- `model_architecture`ï¼šæˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å‹ä½“ç³»ç»“æ„ï¼šåœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹çš„PPO

- `env_id`ï¼šç¯å¢ƒçš„åç§°ï¼Œåœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹`lunarlander-v2`

- `eval_env`ï¼ševal_envä¸­å®šä¹‰çš„è¯„ä¼°ç¯å¢ƒ

- `repo_id`ï¼šå°†åˆ›å»º/æ›´æ–°çš„huggingfaceå­˜å‚¨åº“çš„åç§°`ï¼ˆrepo_id = {username}/{repo_name}ï¼‰`

**è‰¯å¥½èµ·åè§„èŒƒ{ username }/{ model_architecture } - {env_id}**

- `commit_message`ï¼šæäº¤çš„æ¶ˆæ¯


```python
import gymnasium as gym
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.env_util import make_vec_env

from huggingface_sb3 import package_to_hub

## ç›®æ ‡: å®šä¹‰ä¸€ä¸ª repo_id
## repo_id æ˜¯ Hugging Face Hub ä¸­æ¨¡å‹ä»“åº“çš„ idï¼ˆä¾‹å¦‚ï¼Œrepo_id = {organization}/{repo_name}ï¼Œä¾‹å¦‚ ThomasSimonini/ppo-LunarLander-v2ï¼‰repo_id = 

# ç›®æ ‡: å®šä¹‰ç¯å¢ƒåå­—
env_id = 

# åˆ›å»ºä¸€ä¸ªè¯„ä¼°ç¯å¢ƒå¹¶è®¾ç½® render_mode="rgb_array"
eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode="rgb_array")])


# ç›®æ ‡: å®šä¹‰æˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å‹æ¶æ„
model_architecture = ""

## ç›®æ ‡: å®šä¹‰æäº¤ä¿¡æ¯
commit_message = ""

# åœ¨å°†ä»“åº“æ¨é€åˆ° Hub ä¹‹å‰ï¼Œä½¿ç”¨ saveã€evaluate æ–¹æ³•ï¼Œç”Ÿæˆæ¨¡å‹å¡ç‰‡å¹¶è®°å½•ä½ çš„æ™ºèƒ½ä½“çš„é‡æ’­è§†é¢‘
package_to_hub(model=model, # Our trained model
               model_name=model_name, # The name of our trained model 
               model_architecture=model_architecture, # The model architecture we used: in our case PPO
               env_id=env_id, # Name of the environment
               eval_env=eval_env, # Evaluation Environment
               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
               commit_message=commit_message)

# æ³¨æ„ï¼šå¦‚æœåœ¨è¿è¡Œpackage_to_hubå‡½æ•°åå‡ºç°é‡å®šä½é—®é¢˜ï¼Œè¯·è¿è¡Œä»¥ä¸‹ä»£ç 
# cd <path_to_repo> && git add . && git commit -m "Add message" && git pull 
# æœ€åä¸è¦å¿˜è®°æ‰§è¡Œâ€œgit pushâ€å°†æ›´æ”¹æ¨é€åˆ°Hubã€‚
```

#### è§£å†³æ–¹æ³•


```python
import gymnasium as gym

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.env_util import make_vec_env

from huggingface_sb3 import package_to_hub

# å°†ä½ åˆšæ‰åœ¨ä¸Šé¢ä¸¤ä¸ªå•å…ƒæ ¼ä¸­å®šä¹‰çš„å˜é‡æ”¾åœ¨è¿™é‡Œ
# å®šä¹‰ç¯å¢ƒçš„åç§°
env_id = "LunarLander-v2"

# ç›®æ ‡: å®šä¹‰æˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å‹æ¶æ„
model_architecture = "PPO"

## å®šä¹‰ä¸€ä¸ª repo_id
## repo_id æ˜¯ Hugging Face Hub ä¸­æ¨¡å‹ä»“åº“çš„ idï¼ˆä¾‹å¦‚ï¼Œrepo_id = {organization}/{repo_name}ï¼Œä¾‹å¦‚ ThomasSimonini/ppo-LunarLander-v2ï¼‰
## è¯·æ›´æ”¹ä¸ºä½ çš„ REPO ID
repo_id = "ThomasSimonini/ppo-LunarLander-v2" # Change with your repo id, you can't push with mine ğŸ˜„

## ç›®æ ‡: å®šä¹‰æäº¤ä¿¡æ¯
commit_message = "Upload PPO LunarLander-v2 trained agent"

# åˆ›å»ºä¸€ä¸ªè¯„ä¼°ç¯å¢ƒå¹¶è®¾ç½® render_mode="rgb_array"
eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode="rgb_array")])

# å°†ä½ åˆšæ‰å¡«å†™çš„ package_to_hub å‡½æ•°æ”¾åœ¨è¿™é‡Œ

package_to_hub(model=model, # Our trained model
               model_name=model_name, # The name of our trained model 
               model_architecture=model_architecture, # The model architecture we used: in our case PPO
               env_id=env_id, # Name of the environment
               eval_env=eval_env, # Evaluation Environment
               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
               commit_message=commit_message)

```

æ­å–œğŸ¥³ä½ åˆšåˆšè®­ç»ƒå¹¶ä¸Šä¼ äº†ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ã€‚ä¸Šé¢çš„è„šæœ¬åº”æ˜¾ç¤ºæŒ‡å‘æ¨¡å‹å­˜å‚¨åº“çš„é“¾æ¥ï¼Œä¾‹å¦‚ https://huggingface.co/osanseviero/test_sb3ã€‚å½“ä½ è½¬åˆ°æ­¤é“¾æ¥æ—¶ï¼Œä½ å¯ä»¥ï¼š

- åœ¨å³ä¾§æŸ¥çœ‹ä½ çš„æ™ºèƒ½ä½“çš„è§†é¢‘é¢„è§ˆã€‚

- å•å‡»â€œæ–‡ä»¶å’Œç‰ˆæœ¬â€ä»¥æŸ¥çœ‹å­˜å‚¨åº“ä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚

- å•å‡»â€œåœ¨ç¨³å®šçš„ baselines3 ä¸­ä½¿ç”¨â€ä»¥è·å–æ˜¾ç¤ºå¦‚ä½•åŠ è½½æ¨¡å‹çš„ä»£ç æ®µã€‚

- æ¨¡å‹å¡ï¼ˆ`readme.md`æ–‡ä»¶ï¼‰ï¼Œè¯¥å¡ç»™å‡ºäº†æ¨¡å‹çš„æè¿°

åœ¨å¼•æ“ä¸‹ï¼Œä»“åº“ä½¿ç”¨åŸºäºGITçš„å­˜å‚¨åº“ï¼ˆå¦‚æœä½ ä¸çŸ¥é“ Git æ˜¯ä»€ä¹ˆï¼‰ï¼Œè¯·ä¸è¦æ‹…å¿ƒï¼‰ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥åœ¨å®éªŒå’Œæ”¹è¿›æ™ºèƒ½ä½“æ—¶ä½¿ç”¨æ–°ç‰ˆæœ¬æ›´æ–°æ¨¡å‹ã€‚

ä½¿ç”¨æ’è¡Œæ¦œå°† Lunarlander-V2 ä¸åŒå­¦è¿›è¡Œæ¯”è¾ƒğŸ†ğŸ‘‰ https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard

## ä»ä»“åº“åŠ è½½å¹¶ä¿å­˜ä½ çš„ç™»æœˆç€é™†å™¨æ¨¡å‹ğŸ¤—
æ„Ÿè°¢ [ironbar](https://github.com/ironbar) çš„è´¡çŒ®

ä»ä»“åº“åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹éå¸¸ç®€å•

å» https://huggingface.co/models?library=stable-baselines3 æ‰¾æ‰€æœ‰çš„ Stable-baselines3 ä¿å­˜æ¨¡å‹.
1. é€‰æ‹©ä¸€ä¸ªå¤åˆ¶ä¸€ä¸‹ repo_id

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit1/copy-id.png" alt="Copy-id"/>

ç„¶åï¼Œæˆ‘ä»¬åªéœ€è¦ä½¿ç”¨ load_from_hub ä¸ï¼š

- repo_id

- æ–‡ä»¶åï¼šå­˜å‚¨åº“ä¸­çš„ä¿å­˜æ¨¡å‹åŠå…¶æ‰©å±•åï¼ˆ*.zipï¼‰

ç”±äºæˆ‘ä» Hub ä¸‹è½½çš„æ¨¡å‹æ˜¯ç”¨ Gymï¼ˆGymnasium çš„å‰ä¸€ä¸ªç‰ˆæœ¬ï¼‰è®­ç»ƒçš„ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£… shimmyï¼Œè¿™æ˜¯ä¸€ä¸ª API è½¬æ¢å·¥å…·ï¼Œå®ƒå°†å¸®åŠ©æˆ‘ä»¬æ­£ç¡®è¿è¡Œç¯å¢ƒã€‚

Shimmy æ–‡æ¡£ï¼šhttps://github.com/Farama-Foundation/Shimmy

```python
!pip install shimmy
```

```python
from huggingface_sb3 import load_from_hub
repo_id = "Classroom-workshop/assignment2-omar" # The repo_id
filename = "ppo-LunarLander-v2.zip" # The model filename.zip

# When the model was trained on Python 3.8 the pickle protocol is 5
# But Python 3.6, 3.7 use protocol 4
# In order to get compatibility we need to:
# 1. Install pickle5 (we done it at the beginning of the colab)
# 2. Create a custom empty object we pass as parameter to PPO.load()
custom_objects = {
            "learning_rate": 0.0,
            "lr_schedule": lambda _: 0.0,
            "clip_range": lambda _: 0.0,
}

checkpoint = load_from_hub(repo_id, filename)
model = PPO.load(checkpoint, custom_objects=custom_objects, print_system_info=True)
```

è®©æˆ‘ä»¬è¯„ä¼°ä¸€ä¸‹æ™ºèƒ½ä½“


```python
#@title
eval_env = Monitor(gym.make("LunarLander-v2"))
mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)
print(f"mean_reward={mean_reward:.2f} +/- {std_reward}")
```

## ä¸€äº›å…¶ä»–æŒ‘æˆ˜ğŸ†

å­¦ä¹ **çš„æœ€å¥½æ–¹æ³•æ˜¯è‡ªå·±å°è¯•**ï¼å¦‚ä½ æ‰€è§ï¼Œå½“å‰çš„æ™ºèƒ½ä½“ä¸ä½³ã€‚ä½œä¸ºç¬¬ä¸€ä¸ªå»ºè®®ï¼Œä½ å¯ä»¥è®­ç»ƒæ›´å¤šæ­¥éª¤ã€‚æœ‰äº† 1,000,000 æ­¥ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸€äº›ä¸é”™çš„ç»“æœï¼
åœ¨ [æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/deep-reinforcement-learning-leaderboard)ä¸­ï¼Œä½ ä¼šæ‰¾åˆ°ä½ çš„æ™ºèƒ½ä½“ã€‚ä½ èƒ½åˆ·æ¦œå—ï¼Ÿ

è¿™é‡Œæœ‰ä¸€äº›æŠ€å·§å¸®åŠ©ä½ åˆ·æ¦œï¼š

* è®­ç»ƒæ›´å¤šæ­¥éª¤
* å°è¯• `ppo' çš„å…¶ä»–è¶…å‚æ•°ã€‚è¯¦ç»†å‚è€ƒ https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#parameters.
* æŸ¥çœ‹ [Stable-Baselines3 æ–‡æ¡£](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html)å¹¶ä¸”å°è¯•ä¸€ä¸‹å…¶ä»–æ¨¡å‹æ¯”å¦‚ DQN
* å°†**æ–°è®­ç»ƒçš„æ¨¡å‹æ¨åˆ°**ä»“åº“ä¸Š

ä½¿ç”¨ [æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) ğŸ†æ¯”è¾ƒä½ å’Œä½ åŒå­¦çš„ LunarLander-v2ç»“æœ

æœˆäº®ç€é™†ä»»åŠ¡å¤ªæ— èŠäº†å—ï¼Ÿå°è¯•**æ”¹å˜ç¯å¢ƒ**ï¼Œä½¿ç”¨ MountainCar-V0ï¼ŒCartpole-V1 æˆ– Carracing-V0ï¼ŸæŸ¥çœ‹ä»–ä»¬çš„å·¥ä½œåŸç†[ä½¿ç”¨Gymæ–‡æ¡£]ï¼ˆhttps://www.gymlibrary.dev/ï¼‰ï¼Œç¥ä½ ç©çš„å¼€å¿ƒ ğŸ‰ã€‚

æ­å–œå®Œæˆæœ¬ç« ï¼è¿™æ˜¯é‡è¦çš„ä¸€æ­¥

å¦‚æœä½ ä»ç„¶å¯¹æ‰€æœ‰è¿™äº›å…ƒç´ æŸäº›æ„Ÿåˆ°å›°æƒ‘â€¦â€¦é‚£æ˜¯å®Œå…¨æ­£å¸¸çš„ï¼**è¿™å¯¹æˆ‘å’Œæ‰€æœ‰ç ”ç©¶ RL çš„äººéƒ½æ˜¯ä¸€æ ·çš„ã€‚**

èŠ±ç‚¹æ—¶é—´æ‰èƒ½çœŸæ­£æŒæ¡ä¿¡æ¯ï¼Œç„¶åå†å°è¯•å…¶ä»–æŒ‘æˆ˜**ã€‚æŒæ¡è¿™äº›ä¿¡æ¯å¹¶æ‹¥æœ‰åšå®çš„åŸºç¡€å¾ˆé‡è¦ã€‚

è‡ªç„¶ï¼Œåœ¨è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¹¶æ›´æ·±å…¥åœ°è§£é‡Šè¿™äº›æœ¯è¯­ï¼Œä½†æ˜¯**æœ€å¥½åœ¨æ·±å…¥ä¸‹ä¸€ç« ä¹‹å‰å¯¹å®ƒä»¬æœ‰å¾ˆå¥½çš„äº†è§£ã€‚**



ä¸‹æ¬¡ï¼Œåœ¨å¥–åŠ±å•å…ƒ1ä¸­ï¼Œä½ å°†è®­ç»ƒ Huggy ç‹—å»å¼æ£å­ã€‚


<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit1/huggy.jpg" alt="Huggy"/>

## ä¿æŒçƒ­çˆ±ï¼Œå¥”èµ´å±±æµ· ğŸ¤—


