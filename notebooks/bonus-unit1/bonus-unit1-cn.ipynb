{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/bonus-unit1/bonus-unit1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2D3NL_e4crQv"
      },
      "source": [
        "# 奖励单元 1: 让我们训练一只 Huggy 🐶 去叼棍子"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FMYrDriDujzX"
      },
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit2/thumbnail.png\" alt=\"Bonus Unit 1Thumbnail\">\n",
        "\n",
        "在本笔记本中，我们将通过**教 Huggy 狗拿起棍子然后直接在浏览器中玩它**来巩固我们在第一个单元中学到的知识\n",
        "\n",
        "⬇️ 这是**你将在本单元结束时实现的示例。** ⬇️（启动 ▶ 以查看）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnVhs1yYNyUF"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x7oR6R-ZIbeS"
      },
      "source": [
        "### 环境 🎮\n",
        "\n",
        "-  Huggy 狗， [Thomas Simonini](https://twitter.com/ThomasSimonini) 基于 [Puppo The Corgi](https://blog.unity.com/technology/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit)创建的环境\n",
        "\n",
        "### 使用的库 📚\n",
        "\n",
        "- [MLAgents (Hugging Face version)](https://github.com/huggingface/ml-agents)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "60yACvZwO0Cy"
      },
      "source": [
        "我们一直在努力改进我们的教程，所以**如果你在此 Notebook 中发现一些问题**，请[在 Github Repo 上打开一个 issue](https://github.com/huggingface/deep-rl-class/issues)。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oks-ETYdO2Dc"
      },
      "source": [
        "## 本章的目标 🏆\n",
        "\n",
        "\n",
        "在本章的末尾，你将：\n",
        "\n",
        "- 了解**用于训练 Huggy 的状态空间、动作空间和奖励函数**。\n",
        "- **训练你自己的 Huggy** 来拿棍子。\n",
        "- 能够直接在**浏览器中与训练有素的 Huggy 一起玩**。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mUlVrqnBv2o1"
      },
      "source": [
        "## 这本 notebook 来自深度强化学习课程\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pAMjaQpHwB_s"
      },
      "source": [
        "在这门免费的课程中，你将会：\n",
        "\n",
        "- 📖 学习深度强化学习的**理论和实践**。\n",
        "- 🧑‍💻 学习使用一些著名的**深度强化学习库**，比如 Stable Baselines3、RL Baselines3 Zoo、CleanRL 和 Sample Factory 2.0。\n",
        "- 🤖 在**独特的环境**中训练智能体\n",
        "更多详情请查看课程大纲 👉 https://simoninithomas.github.io/deep-rl-course\n",
        "\n",
        "别忘了**<a href=\"http://eepurl.com/ic5ZUD\">报名参加课程</a>** （我们收集你的电子邮件以便在每个单元发布时向你**发送链接并提供有关挑战和更新的信息**）。\n",
        "\n",
        "保持联系的最佳方式是加入我们的 Discord 服务器与社区和我们交流 👉🏻 https://discord.gg/ydHrjt3WP5"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6r7Hl0uywFSO"
      },
      "source": [
        "## 前置条件 🏗️\n",
        "\n",
        "在深入研究该章节之前，你需要：\n",
        "\n",
        "🔲 📚 **通过第 1 单元了解强化学习的基础**（MC、TD、奖励假设...）\n",
        "\n",
        "🔲 📚 **通过奖励单元 1 阅读 Huggy 的介绍**\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DssdIjk_8vZE"
      },
      "source": [
        "## 设置 GPU 💪\n",
        "- - 为了**加速智能体的训练，我们将使用 GPU**。为此，请点击 `Runtime > Change Runtime type`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTfCXHy68xBv"
      },
      "source": [
        "- `Hardware Accelerator > GPU`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "an3ByrXYQ4iK"
      },
      "source": [
        "## 克隆仓库并安装依赖项🔽\n",
        "\n",
        "- 我们需要克隆仓库，它**包含允许你将训练有素的代理推送到 Hub 的实验版本。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WNoL04M7rTa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Clone this specific repository (can take 3min)\n",
        "!git clone https://github.com/huggingface/ml-agents/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8wmVcMk7xKo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Go inside the repository and install the package (can take 3min)\n",
        "%cd ml-agents\n",
        "!pip3 install -e ./ml-agents-envs\n",
        "!pip3 install -e ./ml-agents"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HRY5ufKUKfhI"
      },
      "source": [
        "## 下载并将环境压缩文件移动到 `./trained-envs-executables/linux/` 下\n",
        "\n",
        "- 我们的环境可执行文件位于一个压缩文件中。\n",
        "- 我们需要下载它并将其放置到`./trained-envs-executables/linux/` 位置下\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9Ls6_6eOKiA"
      },
      "outputs": [],
      "source": [
        "!mkdir ./trained-envs-executables\n",
        "!mkdir ./trained-envs-executables/linux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB-G-80GsxYN"
      },
      "outputs": [],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1zv3M95ZJTWHUVOWT6ckq_cm98nft8gdF' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1zv3M95ZJTWHUVOWT6ckq_cm98nft8gdF\" -O ./trained-envs-executables/linux/Huggy.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jsoZGxr1MIXY"
      },
      "source": [
        "使用 `wget` 从 https://drive.google.com/uc?export=download&id=1zv3M95ZJTWHUVOWT6ckq_cm98nft8gdF 下载文件 Huggy.zip。查看在  GDrive 中完整方案并在此处[下载大文件](https://bcrf.biochem.wisc.edu/2021/02/05/download-google-drive-files-using-wget/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FPx0an9IAwO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip -d ./trained-envs-executables/linux/ ./trained-envs-executables/linux/Huggy.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nyumV5XfPKzu"
      },
      "source": [
        "确保你的文件可访问"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dYKVj8yUvj55"
      },
      "source": [
        "## 让我们回顾一下这个环境是如何工作的\n",
        "\n",
        "### The State Space: what Huggy \"perceives.\"\n",
        "\n",
        " Huggy 不会“看到”他的环境。相反，我们向他提供有关环境的信息：\n",
        "\n",
        "- 目标（摇杆）位置\n",
        "- 自己和目标之间的相对位置\n",
        "- 他腿的方向。\n",
        "\n",
        "鉴于所有这些信息， Huggy **可以决定接下来要采取什么行动来实现他的目标**。\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy.jpg\" alt=\"Huggy\" width=\"100%\">\n",
        "\n",
        "\n",
        "### 动作空间： Huggy 可以做什么动作\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy-action.jpg\" alt=\"Huggy action\" width=\"100%\">\n",
        "\n",
        "**关节电机驱动抱腿**。这意味着为了达到目标， Huggy 需要**学会正确地旋转每条腿的关节马达，这样他才能移动**。\n",
        "\n",
        "### 奖励函数\n",
        "\n",
        "奖励函数的设计是为了让 ** Huggy 实现他的目标**：拿到棍子。\n",
        "\n",
        "请记住，强化学习的基础之一是*奖励假设*：目标可以描述为**预期累积奖励**的最大化**。\n",
        "\n",
        "在这里，我们的目标是 Huggy **朝着棍子走去，但不要旋转太多**。因此，我们的奖励函数必须转化为这个目标。\n",
        "\n",
        "我们的奖励函数：\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/reward.jpg\" alt=\"Huggy reward function\" width=\"100%\">\n",
        "\n",
        "- *定向奖励*：我们**奖励他接近目标**。\n",
        "- *时间惩罚*：在每个动作中给予的固定时间惩罚，以**迫使他尽快到达棍子**。\n",
        "- *旋转惩罚*：如果 Huggy 旋转太多并且转得太快**，我们会对 Huggy 进行惩罚。\n",
        "- *达到目标奖励*：我们奖励 Huggy **达到目标**。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NAuEq32Mwvtz"
      },
      "source": [
        "## 检查 Huggy 配置文件\n",
        "\n",
        "- 在 ML-Agents 中，你将**训练超参数定义到 config.yaml 文件中。**\n",
        "\n",
        "- 对于本笔记本的范围，我们不打算修改超参数，但如果你想尝试作为实验，你还应该尝试修改其他一些超参数，Unity 提供了非常好的文档，在这里解释了它们中的每一个] （https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md）。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r9wv5NYGw-05"
      },
      "source": [
        "- **如果你想修改超参数**，在Google Colab notebook中，你可以点击这里打开config.yaml: `/content/ml-agents/config/ppo/Huggy.yaml`\n",
        "\n",
        "- For instance **if you want to save more models during the training** (for now, we save every 200,000 training timesteps). You need to modify:\n",
        "  - `checkpoint_interval`: The number of training timesteps collected between each checkpoint.\n",
        "  - `keep_checkpoints`: The maximum number of model checkpoints to keep. \n",
        "\n",
        "=> Just keep in mind that **decreasing the `checkpoint_interval` means more models to upload to the Hub and so a longer uploading time** \n",
        "We’re now ready to train our agent 🔥."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f9fI555bO12v"
      },
      "source": [
        "## 训练我们的智能体\n",
        "\n",
        "要训​​练我们的智能体，我们只需要**启动 mlagents-learn 并选择包含环境的可执行文件。**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/mllearn.png\" alt=\"ml learn function\" width=\"100%\">\n",
        "\n",
        "使用 ML 智能体，我们运行一个训练脚本。我们定义了四个参数：\n",
        "\n",
        "1. `mlagents-learn <config>`：超参数配置文件所在路径。\n",
        "2. `--env`：环境可执行文件所在的位置。\n",
        "3. `--run_id`：你要为训练运行 ID 指定的名称。\n",
        "4. `--no-graphics`：在训练期间不启动可视化。\n",
        "\n",
        "训练模型并使用 `--resume` 标志在中断的情况下继续训练。\n",
        "\n",
        "> 第一次使用 `--resume` 会失败，尝试再次运行该块以绕过错误。\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lN32oWF8zPjs"
      },
      "source": [
        "训练将需要 30 到 45 分钟，具体取决于你的机器（不要忘记**设置 GPU**），去喝个咖啡☕️放松一下🤗。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS-Yh1UdHfzy"
      },
      "outputs": [],
      "source": [
        "!mlagents-learn ./config/ppo/Huggy.yaml --env=./trained-envs-executables/linux/Huggy/Huggy --run-id=\"Huggy\" --no-graphics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vue94AzPy1t"
      },
      "source": [
        "## 将智能体推送到🤗 Hub\n",
        "\n",
        "- 现在我们已经训练了我们的智能体，我们**准备将其推送到 Hub，以便能够在你的浏览器上与 Huggy 一起玩🔥。**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "izT6FpgNzZ6R"
      },
      "source": [
        "为了能够与社区共享你的模型，还需要执行三个步骤：\n",
        "\n",
        "1️⃣（如果尚未完成）创建一个 HF 帐户 ➡ https://huggingface.co/join\n",
        "\n",
        "2️⃣ 登录，然后，你需要存储来自 Hugging Face 网站的身份验证 token。\n",
        "- 创建一个新 token（https://huggingface.co/settings/tokens）**具有写入权限**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n",
        "\n",
        "- 复制 token\n",
        "- 运行下面的单元格并粘贴 token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKt2vsYoK56o"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ew59mK19zjtN"
      },
      "source": [
        "如果你不想使用 Google Colab 或 Jupyter Notebook，则需要改用此命令：`huggingface-cli login`\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi0y_VASRzJU"
      },
      "source": [
        "然后，我们只需要运行 mlagents-push-to-hf 即可。\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/mlpush.png\" alt=\"ml learn function\" width=\"100%\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KK4fPfnczunT"
      },
      "source": [
        "我们定义了 4 个参数：\n",
        "\n",
        "1. `--run-id`：训练运行id的名称。\n",
        "2. `--local-dir`：代理的保存位置，它是 results/<run_id name=\"None\">，所以在我的例子中是 results/First Training。\n",
        "3. `--repo-id`：你要创建或更新的 Hugging Face 存储库的名称。总是<your huggingface=\"None\" username=\"None\">/<the repo=\"None\" name=\"None\">\n",
        "如果回购不存在**它将自动创建**\n",
        "4. `--commit-message`：由于 HF 存储库是 git 存储库，因此你需要定义提交消息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGEFAIboLVc6"
      },
      "outputs": [],
      "source": [
        "!mlagents-push-to-hf --run-id=\"HuggyTraining\" --local-dir=\"./results/Huggy\" --repo-id=\"ThomasSimonini/ppo-Huggy\" --commit-message=\"Huggy\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yborB0850FTM"
      },
      "source": [
        "否则，如果一切正常，你应该在过程结束时有这个（但使用不同的 url 😆）：\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Your model is pushed to the hub. You can view your model here: https://huggingface.co/ThomasSimonini/ppo-Huggy\n",
        "```\n",
        "\n",
        "它是你的模型存储库的链接。存储库包含一个模型卡，解释如何使用模型、你的 Tensorboard 日志和你的配置文件。 **很棒的是它是一个 git 存储库，这意味着你可以进行不同的提交、使用新推送更新你的存储库、打开 Pull Requests 等。**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/modelcard.png\" alt=\"ml learn function\" width=\"100%\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uaon2cg0NrL"
      },
      "source": [
        "但现在最好的是：**能够在线玩 Huggy 👀。**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VMc4oOsE0QiZ"
      },
      "source": [
        "## 和你的 Huggy 一起玩 🐕\n",
        "\n",
        "这一步最简单：\n",
        "\n",
        "- 在浏览器中打开游戏 Huggy ：https://singularite.itch.io/huggy\n",
        "\n",
        "- 点击玩我的 Huggy 模型\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/load-huggy.jpg\" alt=\"load-huggy\" width=\"100%\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Djs8c5rR0Z8a"
      },
      "source": [
        "1. 在第 1 步中，选择你的模型存储库，即模型 ID（在我的例子中是 ThomasSimonini/ppo-Huggy）。\n",
        "\n",
        "2. 在第 2 步中，**选择你要重播的模型**：\n",
        "  - 我有多个，因为我们每 500000 个时间步保存一个模型。\n",
        "  - 但因为我想要更新的，所以我选择 `Huggy.onnx`\n",
        "\n",
        "👉很棒的是**尝试使用不同的模型步骤来查看代理的改进。**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PI6dPWmh064H"
      },
      "source": [
        "\n",
        "恭喜你完成了这个奖励单元！\n",
        "\n",
        "你现在可以坐下来享受和你的 Huggy 🐶 一起玩耍的乐趣了。并且不要 ** 忘记通过与你的朋友分享 Huggy 来传播热爱 🤗**。如果你在社交媒体上分享它，**请声明我们@huggingface 和我@simoninithomas**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy-cover.jpeg\" alt=\"Huggy cover\" width=\"100%\">\n",
        "\n",
        "\n",
        "## 保持热爱，奔赴山海🤗"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
